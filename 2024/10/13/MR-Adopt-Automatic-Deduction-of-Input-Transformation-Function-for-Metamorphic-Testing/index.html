<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>MR-Adopt: Automatic Deduction of Input Transformation Function for Metamorphic Testing | LinLi's Blog</title><meta name="author" content="Lin Li"><meta name="copyright" content="Lin Li"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="MR-Adopt: Automatic Deduction of Input Transformation Function for Metamorphic TestingABSTRACT尽管最近的研究揭示，许多开发者编写的测试用例可以编码为可重用的变形关系（MR），但其中超过70%直接对源输入和后续输入进行了硬编码。这些编码的MR不包含将源输入转换为相应后续输入的显式输入转换，因此无法通过新的源">
<meta property="og:type" content="article">
<meta property="og:title" content="MR-Adopt: Automatic Deduction of Input Transformation Function for Metamorphic Testing">
<meta property="og:url" content="http://example.com/2024/10/13/MR-Adopt-Automatic-Deduction-of-Input-Transformation-Function-for-Metamorphic-Testing/index.html">
<meta property="og:site_name" content="LinLi&#39;s Blog">
<meta property="og:description" content="MR-Adopt: Automatic Deduction of Input Transformation Function for Metamorphic TestingABSTRACT尽管最近的研究揭示，许多开发者编写的测试用例可以编码为可重用的变形关系（MR），但其中超过70%直接对源输入和后续输入进行了硬编码。这些编码的MR不包含将源输入转换为相应后续输入的显式输入转换，因此无法通过新的源">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2024-10-13T03:09:01.000Z">
<meta property="article:modified_time" content="2024-10-13T03:09:41.053Z">
<meta property="article:author" content="Lin Li">
<meta property="article:tag" content="论文阅读">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2024/10/13/MR-Adopt-Automatic-Deduction-of-Input-Transformation-Function-for-Metamorphic-Testing/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'MR-Adopt: Automatic Deduction of Input Transformation Function for Metamorphic Testing',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-10-13 11:09:41'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">122</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="LinLi's Blog"><span class="site-name">LinLi's Blog</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">MR-Adopt: Automatic Deduction of Input Transformation Function for Metamorphic Testing</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-10-13T03:09:01.000Z" title="发表于 2024-10-13 11:09:01">2024-10-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-10-13T03:09:41.053Z" title="更新于 2024-10-13 11:09:41">2024-10-13</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="MR-Adopt: Automatic Deduction of Input Transformation Function for Metamorphic Testing"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="MR-Adopt-Automatic-Deduction-of-Input-Transformation-Function-for-Metamorphic-Testing"><a href="#MR-Adopt-Automatic-Deduction-of-Input-Transformation-Function-for-Metamorphic-Testing" class="headerlink" title="MR-Adopt: Automatic Deduction of Input Transformation Function for Metamorphic Testing"></a><strong>MR-Adopt: Automatic Deduction of Input Transformation Function for Metamorphic Testing</strong></h1><h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a><strong>ABSTRACT</strong></h2><p>尽管最近的研究揭示，许多开发者编写的测试用例可以编码为可重用的变形关系（MR），但其中超过70%直接对源输入和后续输入进行了硬编码。这些编码的MR不包含将源输入转换为相应后续输入的显式输入转换，因此无法通过新的源输入重用来增强测试充分性。</p>
<p>在本文中，我们提出了MR-Adopt（<strong>自动推导输入转换</strong>），以自动从硬编码的源和后续输入中推导输入转换，旨在使编码的MR能够与新的源输入一起重用。以一个通常只包含一对源输入和后续输入的MR编码测试用例为例，我们利用LLM（大语言模型）理解测试用例的意图并生成额外的源-后续输入对。这有助于引导生成可推广至多个源输入的输入转换。此外，为了缓解LLM生成错误代码的问题，我们通过数据流分析移除与MR无关的代码元素，进一步优化LLM生成的转换。最后，我们基于编码的输出关系评估候选转换并选择最佳转换作为结果。</p>
<p>评估结果表明，MR-Adopt能够生成适用于72.00%编码MR的所有实验源输入的输入转换，这比使用普通GPT-3.5提高了33.33%。通过结合MR-Adopt生成的输入转换，基于MR编码的测试用例可以有效提升测试充分性，分别将代码覆盖率和变异得分提高10.62%和18.91%。</p>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p><font color="red">Background</font></p>
<p><strong>变形测试（MT）</strong>：</p>
<ul>
<li>用于解决测试用例生成和判定问题。</li>
<li>验证的是待测对象（SUT）与定义的变形关系（MRs）的行为，而非单个输入的输出。</li>
<li>每个MR定义：<ul>
<li>一组相关输入之间的<strong>输入关系</strong>。</li>
<li>这些输入的预期输出之间的<strong>输出关系</strong>。</li>
</ul>
</li>
<li>识别出MR后，MT可以通过自动生成的输入（源输入）测试多样的程序行为。</li>
<li>无需为每个输入单独准备判定标准。</li>
<li>已在编译器、数据库等软件的测试中表现出色。</li>
</ul>
<p><strong>识别合适的MRs的重要性</strong>：</p>
<ul>
<li>识别适合SUT的MR是应用MT的关键。</li>
<li>早期方法存在问题：<ul>
<li>劳动密集，特定于某些领域或预定义的MR模式。</li>
<li>产生过于通用且对测试无效的MR。</li>
</ul>
</li>
<li>最近的研究进展：<ul>
<li>开发者经常在测试用例中编码领域知识。</li>
<li>这些编码的MR可以通过自动输入生成技术应用于更多新输入。</li>
<li>提供了更全面的程序测试判定标准。</li>
</ul>
</li>
</ul>
<p><strong>问题描述</strong>：</p>
<ul>
<li>超过70%的MR编码测试用例没有明确的输入关系，而是直接硬编码了源输入和后续输入。</li>
<li>没有明确的输入转换程序，自动生成的源输入无法直接生成相应的后续输入，这限制了这些编码MR的重用，影响了自动化MT和测试充分性的提升。</li>
</ul>
<p><strong>解决方案</strong>：</p>
<ul>
<li>该论文旨在通过从硬编码输入对中推导出明确的输入关系来克服这一障碍。</li>
<li>目标是构建一个输入转换函数，将源输入转换为相应的后续输入，从而使编码的MR能够应用于更多源输入，进行更全面的测试。</li>
</ul>
<p><font color="red">Challenges</font></p>
<p><strong>技术挑战与方法</strong>：</p>
<ul>
<li>该任务可以看作是一个通过示例编程（PBE）的问题，目标是合成一个转换函数，将给定的源输入转换为相应的后续输入。</li>
<li>挑战在于正确解读上下文信息，包括硬编码输入对之间的关系、输出关系以及SUT的属性。</li>
<li>只有一对源输入和后续输入作为示例时，存在程序过拟合于该示例的风险，而无法实现真正的意图。</li>
<li>有效利用上下文信息引导PBE，并生成符合MR语义的通用输入转换函数，以确保其适用于所有潜在的源输入。</li>
</ul>
<p><font color="red">Approach</font></p>
<p><strong>提出MR-Adopt方法</strong>：</p>
<ul>
<li>MR-Adopt 利用大语言模型（LLMs）自动生成MR编码测试用例的输入转换函数。</li>
<li>LLMs具备理解代码和生成代码的能力，能有效挖掘MR的意图和输入关系，生成高质量的输入转换代码。</li>
</ul>
<p><strong>三项设计</strong>：</p>
<ul>
<li><strong>设计1</strong>：通过两阶段实现：<ul>
<li><strong>阶段1</strong>：LLMs根据硬编码的源-后续输入对进行类比推理，推导出服从相同输入关系的新输入对。</li>
<li><strong>阶段2</strong>：LLMs生成基于硬编码输入对和第一阶段生成的额外输入对的输入转换函数。</li>
<li>该设计不仅能减少LLMs过拟合问题，还能提高生成代码的通用性。</li>
</ul>
</li>
<li><strong>设计2</strong>：发现LLMs有时会生成与任务无关的代码片段。MR-Adopt通过数据流分析对LLMs生成的代码进行优化，移除无关片段，并生成正确的输入转换代码。</li>
<li><strong>设计3</strong>：为减轻LLMs生成的相关代码中的错误，MR-Adopt使用开发者编写的输出关系（如断言）作为判定标准验证生成的测试对，并使用额外输入选择最通用的输入转换。</li>
</ul>
<p><strong>结果</strong>：</p>
<ul>
<li>在100个MR编码的测试用例中，MR-Adopt生成了95个可编译的输入转换，其中72个可以推广到所有源输入。</li>
<li>与GPT-3.5相比，MR-Adopt生成了17.28%的更多编译成功的输入转换，并提升了输入对生成的准确性。</li>
<li>整体测试结果表明，MR-Adopt的输入转换大幅提升了测试充分性，提高了代码覆盖率和变异得分。</li>
</ul>
<p><font color="red">Evaluation</font></p>
<p><strong>总体表现</strong>：</p>
<ul>
<li>使用100个开发者编写的MR测试用例对MR-Adopt进行了评估，结果显示其能够为95个MR生成可编译的输入转换，其中72个可以推广到所有源输入。</li>
</ul>
<p><strong>相较于GPT-3.5的提升</strong>：</p>
<ul>
<li>MR-Adopt生成了17.28%更多的可编译转换，生成了33.33%更多的可推广转换。</li>
<li>生成的后续输入覆盖了91.21%的源输入，相较于GPT-3.5提高了122.10%。</li>
</ul>
<p><strong>设计贡献</strong>：</p>
<ul>
<li>消融实验表明，所有三个设计（额外输入对、基于数据流分析的优化和基于输出关系的验证）均对MR-Adopt的整体表现有贡献，其中验证和额外输入对的影响最大。</li>
</ul>
<p><strong>测试充分性提升</strong>：</p>
<ul>
<li>结合输入转换和新源输入，MR-Adopt使代码覆盖率提高了10.62%，变异得分提高了18.91%，验证了其在提高测试充分性方面的实际效果。</li>
</ul>
<p><font color="red">Contribution.</font></p>
<p><strong>创新贡献</strong>：</p>
<ul>
<li>首次为测试用例中的MR编码生成输入转换函数，使得更多编码的MR可以被重用，从而提高SUT的测试充分性。</li>
</ul>
<p><strong>提出MR-Adopt方法</strong>：</p>
<ul>
<li>基于大语言模型（LLMs）的方法，通过生成多个示例输入对来减少过拟合并生成可推广的输入转换。</li>
<li>该方法结合了基于数据流分析的代码优化策略以及验证策略，能够减少LLMs生成的无关错误代码。</li>
</ul>
<p><strong>评估结果</strong>：</p>
<ul>
<li>广泛评估了MR-Adopt在生成输入转换方面的有效性，结果显示72%的输入转换可以推广到所有准备的源输入。</li>
<li>结合这些转换，编码的MR提高了10.62%的代码覆盖率和18.91%的变异得分。</li>
</ul>
<p><strong>数据集构建</strong>：</p>
<ul>
<li>构建了包含100个编码MR的数据集，并在2023年4月1日后发布，连同复制包一起在网站上公开。</li>
</ul>
<h2 id="PRELIMINARIES"><a href="#PRELIMINARIES" class="headerlink" title="PRELIMINARIES"></a><strong>PRELIMINARIES</strong></h2><h3 id="2-1-Metamorphic-Testing"><a href="#2-1-Metamorphic-Testing" class="headerlink" title="2.1 Metamorphic Testing"></a><strong>2.1 Metamorphic Testing</strong></h3><p><strong>定义</strong>：</p>
<ul>
<li>变形测试（MT）通过验证程序是否满足特定的变形关系（MR）来验证程序。MR可以表示为从输入关系到输出关系的逻辑蕴涵。</li>
</ul>
<p><strong>输入和输出关系</strong>：</p>
<ul>
<li>输入关系（Ri）定义了从源输入生成后续输入的规则。</li>
<li>输出关系（Ro）定义了源输入和后续输入对应的预期输出之间的关系。</li>
</ul>
<p><strong>示例</strong>：</p>
<ul>
<li>对于实现正弦函数的程序，可以定义输入关系为后续输入等于负源输入，输出关系为后续输出等于负源输出，基于正弦函数的性质P(x)&#x3D;−P(−x)。</li>
</ul>
<p><strong>变形测试的五个步骤</strong>：</p>
<ol>
<li>构造源输入xs。</li>
<li>执行程序并获取源输出ys。</li>
<li>构造满足输入关系Ri的后续输入xf。</li>
<li>执行程序并获取后续输出yf。</li>
<li>验证两个输出ys和yf是否满足输出关系Ro。</li>
</ol>
<p><strong>输入转换</strong>：</p>
<ul>
<li>输入转换是实现输入关系的函数，负责生成后续输入，可以由开发者编写或通过自动生成的方式（如随机测试）生成。</li>
</ul>
<h3 id="2-2-MR-Encoded-Test-Cases"><a href="#2-2-MR-Encoded-Test-Cases" class="headerlink" title="2.2 MR-Encoded Test Cases"></a><strong>2.2 MR-Encoded Test Cases</strong></h3><p><strong>MR编码测试用例（MTCs）</strong>：</p>
<ul>
<li>MR编码测试用例（MTCs）由Xu等人提出，包含领域特定知识并建议了有用的变形关系（MRs）。</li>
<li>MTCs数量庞大，研究中在701个开源项目中发现了超过11,000个MTCs。</li>
</ul>
<p><strong>MTC的特点</strong>：</p>
<ul>
<li>MTC可看作是已实现的MR实例，通常包含特定的源输入、后续输入、方法调用和断言。</li>
<li>这些MR被很好地编码，并作为判定标准，可应用于新测试输入。</li>
</ul>
<p><strong>例子</strong>：</p>
<ul>
<li>例如，如果一个日期格式的输入应该在另一日期的基础上增加一天，那么编码的MR会验证日期转换函数是否正确处理这种输入关系。</li>
</ul>
<p><strong>问题</strong>：</p>
<ul>
<li>尽管这些实现的MR可以重用并推广到更多新输入，但许多后续输入（如dateB）是通过硬编码而非输入转换程序生成的。</li>
<li>超过70%的MR编码测试用例没有明确的输入转换，从而限制了它们的推广应用。</li>
</ul>
<p><strong>论文中的解决方案</strong>：</p>
<ul>
<li>该论文通过从给定的测试用例及其硬编码输入对中推导出明确的输入关系，解决了这一限制。</li>
<li>目标是构建一个输入转换函数，将源输入转换为后续输入，促进MR的推广应用，增强测试充分性。</li>
</ul>
<h2 id="MR-ADOPT"><a href="#MR-ADOPT" class="headerlink" title="MR-ADOPT"></a><strong>MR-ADOPT</strong></h2><p><img src="/2024/10/13/MR-Adopt-Automatic-Deduction-of-Input-Transformation-Function-for-Metamorphic-Testing/image-20241013103638115.png" alt="image-20241013103638115"></p>
<p><strong>概述</strong>：</p>
<ul>
<li>MR-Adopt使用源输入和后续输入对，以及上下文（如MR编码的测试用例和被测试的方法），生成输入转换函数。</li>
<li>MR-Adopt采用两阶段流水线实现输入转换生成。</li>
</ul>
<p><strong>阶段1</strong>：</p>
<ul>
<li>在第一阶段，MR-Adopt通过类比推理生成额外的源-后续输入对，用作输入关系的示例，从而指导输入转换的生成。</li>
<li>生成候选测试输入对后，通过数据流分析移除无关代码，基于输出关系断言筛选有效输入对。</li>
</ul>
<p><strong>阶段2</strong>：</p>
<ul>
<li>第二阶段，MR-Adopt基于第一阶段的示例对，利用LLM生成输入转换函数。</li>
<li>然后通过进一步移除无关代码和依赖，并将转换函数应用于额外的源输入，最终输出最具通用性的输入转换函数。</li>
</ul>
<p><strong>总结</strong>：</p>
<ul>
<li>MR-Adopt通过生成、优化和验证候选转换函数，确保其生成的输入转换在多种源输入中具有通用性，提升测试的充分性。</li>
</ul>
<h3 id="3-1-Phase-1-Input-Pair-Preparation"><a href="#3-1-Phase-1-Input-Pair-Preparation" class="headerlink" title="3.1 Phase 1: Input Pair Preparation"></a><strong>3.1</strong> <strong>Phase 1:</strong> <strong>Input Pair Preparation</strong></h3><p><strong>输入对生成</strong>：</p>
<ul>
<li>MR-Adopt利用大语言模型（LLM）生成新的源输入和后续输入对。通过模仿给定的输入对并结合现有MTC（测试用例）的上下文，LLM生成这些新的输入对。</li>
<li>生成源输入后，再生成相应的后续输入。该方法采用了“链式思维”（Chain of Thought）策略，逐步生成源输入和后续输入对。</li>
</ul>
<p><strong>输入对的优化</strong>：</p>
<ul>
<li>为了移除无关代码，MR-Adopt执行数据流分析，识别构造后续输入所需的相关代码，并移除不必要的部分。</li>
<li>图4显示了LLM生成的输入对示例，并指出某些输入对无效（如违反MR的输入关系），需要过滤掉这些无效对以避免生成不正确的转换。</li>
</ul>
<p><strong>输入对验证</strong>：</p>
<ul>
<li>MR-Adopt通过MR编码的输出关系验证LLM生成的输入对。具体来说，它根据MTC中的开发者编写的断言检查输出，确保输入对的输出与预期的输出关系一致。</li>
<li>通过这种方式，MR-Adopt筛选出符合输入关系的有效输入对，过滤掉无效或与输出关系不匹配的输入对。</li>
</ul>
<h3 id="3-2-Phase2：Transformation-Generation"><a href="#3-2-Phase2：Transformation-Generation" class="headerlink" title="3.2 Phase2：Transformation Generation"></a>3.2 Phase2：Transformation Generation</h3><p><strong>输入转换生成</strong>：</p>
<ul>
<li>MR-Adopt通过向LLM提供源-后续输入对示例生成候选输入转换函数，这些示例包括硬编码的输入对和第一阶段生成的额外输入对。</li>
<li>提供给LLM的提示中包括系统消息、测试方法代码、输入对、测试用例代码以及输出格式。生成的函数包括函数名、参数列表和返回类型等。</li>
</ul>
<p><strong>输入转换优化</strong>：</p>
<ul>
<li>类似于之前的优化过程，LLM生成的输入转换函数可能包含无关代码，MR-Adopt通过构建依赖图去除无关部分。它跟踪定义输入的语句并递归追踪依赖关系，保留相关的语句，移除不必要的部分。</li>
<li>通过分析生成函数的依赖项，MR-Adopt确保导入的类和包匹配实际需求，解决不准确命名或缺少导入库的问题。</li>
</ul>
<p><strong>输入转换评估</strong>：</p>
<ul>
<li>经过优化后，MR-Adopt进一步通过测试新源输入评估候选转换的通用性。它通过开发者编写的断言（输出关系断言）作为测试判据。</li>
<li>转换函数若能成功生成后续输入并且通过断言，即被视为适用于该源输入。MR-Adopt从所有候选转换中选择适用于最多输入的通用转换。</li>
<li>在多个候选转换适用性相同时，MR-Adopt返回生成的第一个转换作为结果。</li>
</ul>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><h3 id="4-1-Research-Questions"><a href="#4-1-Research-Questions" class="headerlink" title="4.1 Research Questions"></a>4.1 Research Questions</h3><p><strong>RQ1</strong>：MR-Adopt 在生成输入转换方面的效果如何？</p>
<ul>
<li>评估 MR-Adopt 与基准方法在生成通用输入转换函数方面的效果，以确定其生成的输入转换是否适用于多个编码测试用例中的MR。</li>
</ul>
<p><strong>RQ2</strong>：与LLM直接生成输入相比，MR-Adopt 生成的输入转换在构建后续输入时效果如何？</p>
<ul>
<li>通过比较MR-Adopt生成的输入转换函数与LLM直接生成的后续输入，评估使用输入转换函数生成后续输入的好处。</li>
</ul>
<p><strong>RQ3</strong>：MR-Adopt 各个组件的贡献是什么？</p>
<ul>
<li>通过消融研究（Ablation Study），分析MR-Adopt各个组件在生成输入转换中的具体贡献。</li>
</ul>
<p><strong>RQ4</strong>：生成的输入转换如何增强测试充分性？</p>
<ul>
<li>探讨编码MR在结合生成的输入转换后，如何通过新输入重用MR，从而提高对SUT的测试覆盖范围，增强测试充分性。</li>
</ul>
<h3 id="4-2-Dataset"><a href="#4-2-Dataset" class="headerlink" title="4.2 Dataset"></a>4.2 Dataset</h3><p><strong>MR编码测试用例（MTCs）收集</strong>：</p>
<ul>
<li>通过Xu等人的方法，从高质量的Java项目中收集了2007个MTCs，这些项目至少包含200个GitHub stars。</li>
<li>为了确保实验LLM没有在训练期间学习到相关代码，收集的项目均在2023年4月1日之前创建。</li>
<li>选取可以成功编译和执行、并且包含两次方法调用（一个用于源输入，一个用于后续输入）的MTC进行分析，排除了更复杂的包含多个输入组的MR。</li>
</ul>
<p><strong>数据集构建</strong>：</p>
<ul>
<li>最终获得了180个MTC，其中54个有显式的开发者编写的输入转换，126个没有输入转换。</li>
<li>准备了包含两个部分的数据集：(i) 没有输入转换的100个MTC作为任务，(ii) 对应的输入转换函数作为标准答案。</li>
</ul>
<p><strong>输入转换任务构建</strong>：</p>
<ul>
<li>试图利用所有54个有标准答案的MTC，将开发者编写的输入转换应用于硬编码的源输入来生成后续输入。</li>
<li>构建了36个任务，使用开发者的转换函数替换硬编码的后续输入。</li>
<li>对于没有开发者编写的输入转换的MTC，手动构建了转换函数，并在两个作者间协作评审解决分歧，最终花费了约200小时完成任务构建。</li>
</ul>
<h3 id="4-3-Environment-and-Large-Language-Models"><a href="#4-3-Environment-and-Large-Language-Models" class="headerlink" title="4.3 Environment and Large Language Models"></a><strong>4.3 Environment and Large Language Models</strong></h3><p><strong>硬件环境</strong>：</p>
<ul>
<li>实验使用的机器配置包括三张RTX 4090显卡、双Intel Xeon E5-2683 v4 CPU和256 GB内存。</li>
</ul>
<p><strong>使用的大语言模型（LLMs）</strong>：</p>
<ul>
<li>评估中使用的LLMs包括：<ul>
<li>GPT-3.5（来自OpenAI）</li>
<li>Llama3-8B（来自Meta）</li>
<li>Deepseek-coder-7b（来自DeepSeek）</li>
<li>CodeQwen1.5-7B-Chat（来自阿里巴巴）</li>
</ul>
</li>
<li>选择这些模型是因为它们属于知名的LLM系列且可在实验环境中部署。</li>
</ul>
<h3 id="4-4-Source-Input-Preparation"><a href="#4-4-Source-Input-Preparation" class="headerlink" title="4.4 Source Input Preparation"></a><strong>4.4 Source Input Preparation</strong></h3><p><strong>挑战</strong>：</p>
<ul>
<li>为了评估生成的输入转换，需要有效的源输入作为“测试集”。然而，自动化测试输入生成工具（如Evosuite和Randoop）对于超过50%的MR难以生成有效输入，因为这些输入通常是用户定义的复杂对象，具有复杂的前提条件和环境。</li>
</ul>
<p><strong>使用LLM生成源输入</strong>：</p>
<ul>
<li>最近的研究表明，大语言模型（LLMs）是很好的测试输入生成器。因此，研究中使用了Qwen LLM生成新的源输入用于评估转换。</li>
<li>为避免循环评价，使用不同的LLM分别生成“测试集”以及用于MR-Adopt中的输入对和转换函数。</li>
</ul>
<p><strong>过程</strong>：</p>
<ul>
<li>Qwen每次生成5个源输入，并重复了10次，使用0.2的温度设置生成更多的源输入。</li>
<li>Qwen共生成了5,535个源输入，经过去重后得到2,477个输入。随后，通过执行对应的输入转换来验证这些输入是否有效。</li>
<li>源输入被认为有效的标准是：它能成功生成后续输入，并通过开发者编写的断言。</li>
<li>Qwen在一些复杂且具有严格领域限制的对象上无法生成新的有效输入，最终共收集到1,366个有效源输入，平均每个MR有14.37个。</li>
</ul>
<h3 id="4-5-RQ1-Effectiveness-of-MR-Adopt"><a href="#4-5-RQ1-Effectiveness-of-MR-Adopt" class="headerlink" title="4.5 RQ1: Effectiveness of MR-Adopt"></a><strong>4.5 RQ1: Effectiveness of MR-Adopt</strong></h3><p><strong>RQ1：MR-Adopt的有效性</strong>的概括：</p>
<ol>
<li><strong>实验设置</strong>：<ul>
<li>该研究问题旨在检查MR-Adopt生成输入转换函数的效果，重点在于它们的可编译性和通用性。</li>
<li>采用了GPT-3.5、Llama3-8B、Deepseek-coder-7b作为基线模型，直接提示这些模型生成输入转换，并将结果与MR-Adopt进行比较。</li>
<li>度量指标包括生成的可编译转换函数数量和生成的通用转换函数数量（即至少适用于75%的源输入）。</li>
</ul>
</li>
<li><strong>结果</strong>：<ul>
<li>MR-Adopt与GPT-3.5结合时效果最佳，生成了95个可编译的转换函数，其中72个通用于所有源输入。</li>
<li>与Llama3和Deepseek结合时，MR-Adopt分别生成了68个和71个通用转换。</li>
<li>相比之下，直接提示LLMs生成的转换函数在处理常见案例时效果较好，但在处理边界案例时遇到困难，生成的转换往往依赖于错误的方法或受限的API。</li>
</ul>
</li>
<li><strong>对比结果</strong>：<ul>
<li>MR-Adopt显著优于基线LLMs，特别是在生成可编译转换和通用转换方面，改进幅度在16.66%到33.33%之间。</li>
<li>MR-Adopt通过细化生成过程和评估策略，成功生成了适用于大部分源输入的转换，尤其是在生成75%或以上通用转换时表现出色。</li>
</ul>
</li>
</ol>
<p><strong>结论</strong>： MR-Adopt在所有指标上均显著优于基线LLMs，生成了更多的可编译和通用输入转换函数，提升了33.33%的通用性。</p>
<h3 id="4-6-RQ2-Effectiveness-of-Input-Transformations"><a href="#4-6-RQ2-Effectiveness-of-Input-Transformations" class="headerlink" title="4.6 RQ2: Effectiveness of Input Transformations"></a><strong>4.6</strong> <strong>RQ2: Effectiveness of Input Transformations</strong></h3><p><strong>实验设置</strong>：</p>
<ul>
<li>该研究问题旨在评估MR-Adopt生成的输入转换函数在生成有效后续输入方面的效果，并与直接使用LLMs生成的输入对进行对比。</li>
<li>使用1,366个准备好的源输入（从之前步骤生成）作为测试集，测量有效后续输入的数量。</li>
</ul>
<p><strong>结果</strong>：</p>
<ul>
<li>MR-Adopt与GPT-3.5结合时，生成了1,246个有效后续输入，覆盖了91.22%的源输入。</li>
<li>与直接使用LLMs生成的输入对相比，MR-Adopt的有效后续输入数量分别提升了72.10%到108.71%（与Llama3、Deepseek和GPT-3.5相比）。</li>
</ul>
<p><strong>比较和分析</strong>：</p>
<ul>
<li>增强版的LLMs（结合MR-Adopt的优化过程）生成了更多有效后续输入，分别提升了61.82%（与Llama3相比）、69.06%（与Deepseek相比）、75.99%（与GPT-3.5相比）。</li>
<li>这表明MR-Adopt的两阶段管道以及准备-优化-验证流程有效提升了输入转换的质量。</li>
<li>相比之下，直接使用LLMs生成的后续输入往往存在错误值或无法捕捉多个输入参数之间的约束问题，而MR-Adopt能够更好地处理这些问题。</li>
</ul>
<p><strong>总结</strong>：</p>
<ul>
<li>MR-Adopt的优化步骤有效提升了后续输入的生成质量，与GPT-3.5相比最多提升了18.59%。</li>
<li>MR-Adopt生成的输入转换函数能够为91.22%的源输入生成有效的后续输入，显著超过基线LLMs。</li>
</ul>
<h3 id="4-7-RQ3-Ablation-Study-on-MR-Adopt"><a href="#4-7-RQ3-Ablation-Study-on-MR-Adopt" class="headerlink" title="4.7 RQ3: Ablation Study on MR-Adopt"></a><strong>4.7 RQ3: Ablation Study on MR-Adopt</strong></h3><p><strong>实验设置</strong>：</p>
<ul>
<li>通过消除MR-Adopt中的三个关键组件，创建了三个变体来分析每个设计对生成通用输入转换的帮助：<ul>
<li><strong>v1</strong>：不使用额外的输入对。</li>
<li><strong>v2</strong>：不进行优化步骤。</li>
<li><strong>v3</strong>：不进行评估步骤。</li>
</ul>
</li>
</ul>
<p><strong>结果</strong>：</p>
<ul>
<li><strong>v1</strong>（没有额外输入对）导致100%通用转换的生成减少了19.44%。这表明额外的输入对有助于解决过拟合问题，帮助生成更通用的转换。</li>
<li><strong>v2</strong>（没有优化步骤）导致100%通用转换减少了15.27%。这表明优化步骤能够修正生成中的小问题，移除无关代码，从而生成更有效的转换。</li>
<li><strong>v3</strong>（没有评估步骤）导致100%通用转换减少了22.22%。这表明评估步骤对选择最通用的转换函数至关重要，随机选择可能会错过最优解。</li>
</ul>
<p><strong>结论</strong>：</p>
<ul>
<li>研究表明，MR-Adopt的三个设计（额外输入对、优化步骤和评估步骤）都对生成通用输入转换有重要贡献。</li>
<li>评估步骤对MR-Adopt效果的贡献最大，额外输入对和优化步骤贡献相似。</li>
</ul>
<h3 id="4-8-RQ4-Usefulness-of-Input-Transformations"><a href="#4-8-RQ4-Usefulness-of-Input-Transformations" class="headerlink" title="4.8 RQ4: Usefulness of Input Transformations"></a><strong>4.8 RQ4: Usefulness of Input Transformations</strong></h3><p><strong>实验设置</strong>：</p>
<ul>
<li>该研究问题旨在评估MR-Adopt生成的输入转换在增强测试充分性方面的效果。</li>
<li>通过将生成的输入转换整合到MTCs中构建新测试用例（M），并与两种基线进行比较：(i) 开发者编写的MR测试用例（D）和 (ii) LLM生成的后续输入对（L）。</li>
</ul>
<p><strong>测试充分性评估</strong>：</p>
<ul>
<li>使用<strong>代码覆盖率</strong>（执行的代码行百分比）和<strong>变异分数</strong>（被测试用例杀死的变异体百分比）作为测试充分性的指标。</li>
<li>测试采用Mutation Testing工具Pitest，针对目标类中由MR涉及的方法计算变异分数。</li>
</ul>
<p><strong>结果</strong>：</p>
<ul>
<li>与开发者编写的测试用例（D）相比，整合了MR-Adopt生成的输入转换的新测试用例（D+M）提升了代码覆盖率10.62%，变异分数提升了18.91%。</li>
<li>即使对比经过LLM增强的输入对（D+L），新测试用例（D+L+M）也表现出4.25%的代码覆盖率提升和5.67%的变异分数提升。</li>
</ul>
<p><strong>结论</strong>：</p>
<ul>
<li>MR-Adopt生成的输入转换通过生成更多的有效后续输入，扩展了对SUT行为的覆盖，显著增强了测试充分性。</li>
<li>生成的新测试用例展示了MR-Adopt在提高测试覆盖范围和识别更多潜在缺陷方面的实际效用。</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Lin Li</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/10/13/MR-Adopt-Automatic-Deduction-of-Input-Transformation-Function-for-Metamorphic-Testing/">http://example.com/2024/10/13/MR-Adopt-Automatic-Deduction-of-Input-Transformation-Function-for-Metamorphic-Testing/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">LinLi's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/10/19/SMT-Solver-Validation-Empowered-by-Large-Pre-trained-Language-Models/" title="SMT Solver Validation Empowered by Large Pre-trained Language Models"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">SMT Solver Validation Empowered by Large Pre-trained Language Models</div></div></a></div><div class="next-post pull-right"><a href="/2024/10/12/Domain-Adaptation-for-Code-Model-Based-Unit-Test-Case-Generation/" title="Domain Adaptation for Code Model-Based Unit Test Case Generation"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Domain Adaptation for Code Model-Based Unit Test Case Generation</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/03/04/PLUMBER/" title="PLUMBER"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-04</div><div class="title">PLUMBER</div></div></a></div><div><a href="/2023/03/08/%E9%80%9A%E8%BF%87NPM%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BE%9D%E8%B5%96%E6%A0%91%E6%8F%AD%E5%BC%80%E8%84%86%E5%BC%B1%E6%80%A7%E4%BC%A0%E6%92%AD%E5%8F%8A%E5%85%B6%E6%BC%94%E5%8C%96%E7%9A%84%E7%A5%9E%E7%A7%98%E9%9D%A2%E7%BA%B1/" title="通过NPM生态系统的依赖树揭开脆弱性传播及其演化的神秘面纱"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-08</div><div class="title">通过NPM生态系统的依赖树揭开脆弱性传播及其演化的神秘面纱</div></div></a></div><div><a href="/2023/04/03/Flexible-and-Optimal-Dependency-Management-via-Max-SMT/" title="Flexible and Optimal Dependency Management via Max-SMT"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-03</div><div class="title">Flexible and Optimal Dependency Management via Max-SMT</div></div></a></div><div><a href="/2023/04/11/What-the-Fork-Finding-Hidden-Code-Clones-in-npm/" title="What the Fork Finding Hidden Code Clones in npm"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-11</div><div class="title">What the Fork Finding Hidden Code Clones in npm</div></div></a></div><div><a href="/2023/04/12/Static-Type-Inference-for-Foreign-Functions-of-Python/" title="Static Type Inference for Foreign Functions of Python"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-12</div><div class="title">Static Type Inference for Foreign Functions of Python</div></div></a></div><div><a href="/2023/04/13/Where-to-Start-Studying-Type-Annotation-Practices-in-Python/" title="Where to Start Studying Type Annotation Practices in Python"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-13</div><div class="title">Where to Start Studying Type Annotation Practices in Python</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Lin Li</div><div class="author-info__description">今日事，今日毕</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">122</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#MR-Adopt-Automatic-Deduction-of-Input-Transformation-Function-for-Metamorphic-Testing"><span class="toc-number">1.</span> <span class="toc-text">MR-Adopt: Automatic Deduction of Input Transformation Function for Metamorphic Testing</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#ABSTRACT"><span class="toc-number">1.1.</span> <span class="toc-text">ABSTRACT</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#INTRODUCTION"><span class="toc-number">1.2.</span> <span class="toc-text">INTRODUCTION</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PRELIMINARIES"><span class="toc-number">1.3.</span> <span class="toc-text">PRELIMINARIES</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-Metamorphic-Testing"><span class="toc-number">1.3.1.</span> <span class="toc-text">2.1 Metamorphic Testing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-MR-Encoded-Test-Cases"><span class="toc-number">1.3.2.</span> <span class="toc-text">2.2 MR-Encoded Test Cases</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MR-ADOPT"><span class="toc-number">1.4.</span> <span class="toc-text">MR-ADOPT</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Phase-1-Input-Pair-Preparation"><span class="toc-number">1.4.1.</span> <span class="toc-text">3.1 Phase 1: Input Pair Preparation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-Phase2%EF%BC%9ATransformation-Generation"><span class="toc-number">1.4.2.</span> <span class="toc-text">3.2 Phase2：Transformation Generation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Evaluation"><span class="toc-number">1.5.</span> <span class="toc-text">Evaluation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Research-Questions"><span class="toc-number">1.5.1.</span> <span class="toc-text">4.1 Research Questions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Dataset"><span class="toc-number">1.5.2.</span> <span class="toc-text">4.2 Dataset</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-Environment-and-Large-Language-Models"><span class="toc-number">1.5.3.</span> <span class="toc-text">4.3 Environment and Large Language Models</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-Source-Input-Preparation"><span class="toc-number">1.5.4.</span> <span class="toc-text">4.4 Source Input Preparation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-RQ1-Effectiveness-of-MR-Adopt"><span class="toc-number">1.5.5.</span> <span class="toc-text">4.5 RQ1: Effectiveness of MR-Adopt</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-6-RQ2-Effectiveness-of-Input-Transformations"><span class="toc-number">1.5.6.</span> <span class="toc-text">4.6 RQ2: Effectiveness of Input Transformations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-7-RQ3-Ablation-Study-on-MR-Adopt"><span class="toc-number">1.5.7.</span> <span class="toc-text">4.7 RQ3: Ablation Study on MR-Adopt</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-8-RQ4-Usefulness-of-Input-Transformations"><span class="toc-number">1.5.8.</span> <span class="toc-text">4.8 RQ4: Usefulness of Input Transformations</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/08/%E8%A7%A3%E5%86%B3Camera-ready-%E2%9C%98-Problem-Not-all-fonts-are-embedded-%E9%97%AE%E9%A2%98/" title="解决Camera ready ✘ Problem: Not all fonts are embedded. 问题">解决Camera ready ✘ Problem: Not all fonts are embedded. 问题</a><time datetime="2025-04-08T14:19:21.000Z" title="发表于 2025-04-08 22:19:21">2025-04-08</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/21/Sequence-Oriented-DBMS-Fuzzing/" title="Sequence-Oriented DBMS Fuzzing">Sequence-Oriented DBMS Fuzzing</a><time datetime="2025-02-21T09:35:08.000Z" title="发表于 2025-02-21 17:35:08">2025-02-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/18/AGENTLESS-Demystifying-LLM-based-Software-Engineering-Agents/" title="AGENTLESS: Demystifying LLM-based Software Engineering Agents">AGENTLESS: Demystifying LLM-based Software Engineering Agents</a><time datetime="2025-02-18T12:16:29.000Z" title="发表于 2025-02-18 20:16:29">2025-02-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/01/DeepSeek-R1-Incentivizing-Reasoning-Capability-in-LLMs-via-Reinforcement-Learning/" title="DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning">DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</a><time datetime="2025-02-01T11:11:48.000Z" title="发表于 2025-02-01 19:11:48">2025-02-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/01/DeepSeek-Coder-When-the-Large-Language-Model-Meets-Programming-The-Rise-of-Code-Intelligence/" title="DeepSeek-Coder: When the Large Language Model Meets Programming - The Rise of Code Intelligence">DeepSeek-Coder: When the Large Language Model Meets Programming - The Rise of Code Intelligence</a><time datetime="2025-02-01T02:43:19.000Z" title="发表于 2025-02-01 10:43:19">2025-02-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Lin Li</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>